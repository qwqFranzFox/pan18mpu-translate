// 使用typst packages库，则使用
// #import "@preview/unofficial-sdu-thesis:1.0.0": * //上一版本为0.2.2

// 如果是本地安装，则使用
// #import "@local/unofficial-sdu-thesis:1.0.0": *

// 如果是源码调试，则使用
#import "../lib.typ": *

#let (
  info,
  doc,
  cover,
  declare,
  appendix,
  outline,
  mainmatter,
  conclusion,
  abstract,
  bib,
  acknowledgement,
  under-cover,
) = documentclass(
  info: (
    title: "基于MPU的微控制器上的可预测虚拟化",
    name: "袁铭骏",
    id: "202500130194",
    school: "计算机科学与技术学院",
    major: "计算机类",
    grade: "2025级",
    mentor: "无",
    time: "2025年12月19日",
  ),

  // 此项控制是否开启匿名模式，开启后自动匹配全文范围的导师名MENTORNAME，替换为****
  if-mentor-anonymous: false,
)

#show: doc

// 封面
#cover()

#align(center)[#heading(outlined: false, level: 1)[基于MPU的微控制器上的可预测虚拟化]]
#align(center)[潘润宇，Gregor Peach，任玉鑫，Gabriel Parmer]
#align(center)[2018 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)]

#abstract(
  body: [
    随着嵌入式系统深入用户市场，产生了对它们的廉价、可预测性、可靠性以及安全性的要求。由于这些系统经常连接网络且运行来各种来源的代码，可靠性和安全性变得尤为重要。为了维持低成本和低功耗，很多嵌入式系统只使用存储极为有限的微控制器（大体上128KB的SRAM）。不幸的是，这些系统的隔离和保护设施通常缺乏生气
    #footnote[本文中个人没有很好的译法的、拥有特定含义的特定词语，保留原样不做翻译。有个人觉得可翻译但不能完全传达意思的，在脚注中用“译注:
      xxx”标出。]
    #footnote[译注: lackluster]，使得有条理的可靠性和安全性保障难以实现。

    这篇论文详细介绍了在小型微控制器上CPU、内存、I/O这三个维度的隔离。一个关键的挑战是给出一种有效地利用微控制器上硬件内存保护设施的方法。这可以通过结合静态分析，充分利用硬件保护设施，以及基于我们的CompositeOS的一个运行时来实现。在这个基础上，我们构建了一个可以可预测地运行多个嵌入式实时操作系统的虚拟化基础架构。我们展示了基于FreeRTOS的虚拟机可以取得不错的效率和可预测性，同时可以轻松地扩展到在512KB
    SRAM上运行8个VM。
  ],
  keywords: ("实时", "虚拟化", "IoT", "MPU"),
  body-en: [
    With the increasing penetration of embedded systems into the consumer market there is a pressure to have all of inexpensiveness, predictability, reliability, and security. As these systems are often attached to networks and execute complex code from varying sources, reliability and security become essential. To maintain low price and small power budgets, many systems use small microcontrollers with limited memory (on the order of 128KB of SRAM). Unfortunately, the isolation and protection facilities of these systems are often lackluster, making a principled treatment of reliability and security difficult.
    This paper details a system that provides isolation along the three dimensions of CPU, memory, and I/O on small microcontrollers. A key challenge is providing a effective means of harnessing the limited hardware memory protection facilities of microcontrollers. This is achieved through a combination of a static analysis to make the most of limited hardware protection facilities, and a run-time based on our Composite OS. On this foundation, we build a virtualization infrastructure to execute multiple embedded real-time operating systems predictably. We show that VMs based on FreeRTOS achieve reasonable efficiency and predictability, while easily enabling scaling up to 8 VMs in 512 KB SRAM.
  ],
  keywords-en: (
    "Real-time",
    "Virtualization",
    "IoT",
    "MPU",
  ),
)

#outline()

#show: mainmatter

// #show ref.where(label:"")

//===========开始正文============

= 绪论 <I>

随着嵌入式计算和物联网（IoT）的兴起，在保持必需的可预测性的前提下，保证这些系统背后的计算架构稳定而安全显得尤为重要。这些系统的持续增长的应用正驱动着物联网设备标志性的“无处不在的连接”。有了网络连接，随之而来的是它提供给恶意攻击者与系统接触的能力，以及相关的安全问题。同时，可定制地过滤和处理传感器数据的操作，也使得这些系统逐渐远离静态代码的范畴。更进一步，我们注意到这些系统的开发逐渐趋向去中心化。来自不同客户/系统设计师的、在不同安全级别上的代码，必须运行在同一个设备上。这种多租户、#emph[混合关键性]@mixed-criticality
又推动了强隔离。

在这些嵌入式系统之外，改善系统可靠性和安全性的传统方法通常依赖不断增长的隔离。例如，类似页表的硬件设施的引入用于隔离内存，以防止错误或损害的无限制传播。然而，由于成本、大小、重量和功耗（SWaP,
Size, Weight, and
Power）的限制，在嵌入式和物联网领域，用于隔离的硬件设施通常也十分有限。尤其在这些系统中最廉价和最具能效比的种类中，一个重要的问题是，我们能否既提供实时的可预测执行，又给出所需的隔离设施。

一个内存保护单元（MPU, Memory Protection
Unit），是一种可以在很多微控制器上找到的简单的硬件内存隔离功能。与内存管理单元（MMU,
Memory Management
Units）不同，MPU不提供虚拟和物理地址之间的页级转换。相反，MPU提供对物理地址区间的访问控制。在需要低功耗、高可靠性、廉价和简单的系统上非常流行。由于片上有限的与处理器频率相当的SRAM，这些系统通常避免使用数据缓存或使用非常小的缓存。MPU不使用内存内的结构来跟踪内存可用性，因此内存访问时间变化相对较小。与之相对地，MMU通常使用页表和配对的翻译后备缓冲表（TLB,
Translation Lookaside
Buffer）。TLB未命中需要遍历页表，并且对内存访问时间有显著的抖动影响。因此，MPU对于不太需要应用内存灵活性的情况下，尤其是在TLB的大小远小于应用所需的页面数量的系统中，具有一定价值。在这些情景下，显著更低的内存访问抖动提高了可预测性，使得基于MPU的系统能够从中受益。基于在微控制器中MPU的广泛开发，这篇论文将介绍一个基于Composite
#math.mu\-kernel操作系统@scale-pred 的处理器，用于提供更好的可靠性和安全性。


不同的微控制器有迥异的MPU配置，在大小、对齐方式，以及可以保护的内存区域的数目方面都有差异。这些变化的限制意味着大多数嵌入式操作系统都提供为MPU编程的特定API。相比之下，这篇文章中，我们使用具有一个强访问控制模型的现存的操作系统（Composite），同时为MMU和MPU推广它的内存保护设施。这启发了基于路径压缩的基数Tries（PCTries,
Path-Compressed radix
Tries）的通用API，能够在推广上述两种硬件保护机制的同时，维持系统的可预测性属性。这个系统将保护域抽象为封装了用户级代码、数据和线程运行的#emph[组件（Component）]。一个组件是建立在一个硬件内存保护上下文和一个capability表@capability
上的轻量级抽象，两者都限制了组件对于系统资源的访问。组件实现了调度、内存映射/访问控制（基于PCTries）和I/O等系统资源管理策略，从而不仅为应用，也为系统服务提供了隔离。


Composite使用了PCTries来支持MPU，提供了微控制器内存隔离的基础。然而，为了提供租户之间、不同来源或安全登记的代码之间的强隔离，或者当错误可以被更多地允许时，CPU和I/O的隔离也是必须的。因此，这篇文章结合了带有分级调度@hires
的PCTrie支持和一个抽象并限制了I/O访问以提供CPU和I/O隔离的组件。这里，系统调度器@temp-cap@pred-inter\和I/O管理器运行在用户级，共同实现了一个虚拟机监视器（VMM,
Virtual Machine Monitor）@nova ，使得虚拟机（VMs, Virtual
Machines）可以可预测地、隔离地运行传统的实时操作系统（RTOS, Real-Time Operating
System）。据我们所知，这是第一个为基于MPU的微控制器设计的虚拟化系统。

#strong[贡献]。我们从讨论MPU的背景（@II）开始，然后集中在这篇论文的贡献：
- 一个通过智能地排列组件内存和潜在的共享映射来实现对MPU有限资源的利用的（@III）。
- 基于PCTries的内存访问控制和内核交互的设计（@IV）和实现（@V），以及一个现有的内核的使用它的改进版。
- 一个提供资源多路复用和CPU、内存、I/O隔离的资源有限的半虚拟化架构（@VI）。
- 最终，我们提供一个基于PCTries的Composite的评估，以及其虚拟化架构与现有的（非虚拟化的）RTOSes的对比（@VII）。

= 嵌入式系统硬件和内存保护 <II>

为了更好地理解充分利用MPU以构建复杂的虚拟化架构隔离配置的困难，我们回顾MMU和MPU的配置细节。

== 页表和内存管理单元 <II-A>

页表在高端CPU中无处不在，他们提供（1）页级保护和（2）通过虚拟地址和物理地址之间的翻译实现的内存访问虚拟化。这种虚拟化让物理内存布局和运行内存解耦，同时也使得不同组件的虚拟地址可以重合。一种常见的MMU结构基于以基数Trie实现的页表。响应一个加载或储存操作时，硬件页表遍历逻辑启动以在虚拟地址和物理地址之间转译。为了减少这种每次内存访问都会进行的遍历操作的巨大开支，翻译后备缓冲表（TLB）缓存一定数量的翻译条目。TLB未命中对性能和可预测性的影响是显著的。这促使了基于染色@tlb-coloring\来提高翻译缓存内的隔离性的TLB分区。另外，MMU使精细的隔离更加复杂，并且可以导致严重的损耗@singularity。为了增加TLB缓存的虚拟地址数量，一种常见的方法是使用超级页@superpages。

== 内存保护单元 <II-B>

#set figure(supplement: [图])

#figure(
  caption: [MMU 和 MPU的区别。MMU进行基于页的翻译，用虚线标出；相反地，MPU使用基于域的保护，用竖直的实线标出。RX：只读&可执行；RO：只读；RW：读写。],
  image("./img/fig-1.gif"),
)<fig-1>

嵌入式系统在历史上设计用于执行特定的人物，从而使得代码可以特殊化，并且不需要功能丰富、通用的系统。这导致了它们有更慢的处理器（ARM
Cortex-M
处理器主频通常在10-300MHz），以及更小的内存（16-1024KB）。有限的内存大小意味着内存通常是SRAM，和逻辑芯片同在芯片内，并且以和逻辑部分差不多的频率运行。这就避免了在内存和逻辑处理器之间设计巨大的缓存，从而更加简化芯片设计，减少功耗需求，提高软件执行的可预测性。在这种环境下，页表所需的内存，由于页粒度管理导致的内部碎片化，以及TLB访问导致的内存访问不断增加的变化，是不理想的。相比之下，MPU访问控制状态是在仅内核态可编程的寄存器里直接管理的，并且有更灵活的颗粒度控制。不幸的是，由于MPU并不提供地址虚拟化，所有的内存必须是不重叠的，从而必须实现一个单地址空间操作系统（SASOS,
Single Address Space Operating System）@opal。

许多嵌入式系统架构，包括ARM
Cortex-M，MIPS,PowerPC和AVR32，都提供MPU。尽管MPU的实现之间略有不同，我们在这里给出一个普遍形式。MPU提供一定量的#emph[区域（regions）]${ r_0 \, r_1 \, dots } = cal(R)$，一个区域$r_i$，可以被配置成保护保护从$a_i$开始，长度为$s_i$的一片内存。每个区域$r_i$，有$S$个#emph[子区域（subregions）]，每个子区域覆盖$s_i \/ S$大小的内存。$s_i$的限制为有最小值$s_i gt.eq caron(s)$，并且可能需要是一个2的幂次方。每个区域和子区域有一些访问权限的集合，包括${ upright("readable") \, upright("writable") }$。默认地，在用户态代码中不能访问内存，而区域和子区域定义了哪些内存区域可以以哪些类型的内存操作进行访问。区域通常有对齐限制$cal(A)$，既有常量对齐（例如在字的边界，$cal(A) = \( a_i mod med 4 = 0 \)$），或者特定大小对齐的边界（例如$cal(A) = \( a_i mod med s_i = 0 \)$）。

#strong[MPU 示例]。许多 ARM Cortex-M 微处理器，例如
Cortex-M7，有配置为$\| cal(R) \| = 1$到$16$，$S = 8$，$cal(A) = \( a_i mod med s_i = 0 \)$，$caron(s) = 32$，并且$s_i$必须是2的幂次方。每个区域有在${ upright("readable") \, upright("writable") }$内的访问权限，同时每个子区域继承上级区域的权限，并额外有一个位用于可用性。MIPS
M14k
更加简单，$\| cal(R) \| = 1$到$16$，$S = 1$，$cal(A) = \( a_i mod med 4 = 0 \)$，且$caron(s) = 4$。在本研究中，我们集中研究
ARM Cortex-M 微处理器，不仅因为他们广泛应用且流行，也是因为他们有某些最复杂的
MPU 限制。

== I/O和非易失性存储 <II-C>

许多微控制器都支持在闪存的固定虚拟地址#emph[就地执行]只读的内存。这使得有限的
SRAM
可以只被可写的内存占据。相似地，大多数I/O设备是映射到内存上的并且使用加载和存储操作进行直接访问的。为了限制不同的应用程序对这些区域的访问，MPU
区域和子区域必须被合理利用。当一个 MPU
的区域的对齐或颗粒度限制阻止对单独的设备地址区域进行保护时，对它们的访问必须由一个服务管理调节（如@io-virt）。

== 嵌入式系统对 MPU 的应用 <II-D>
FreeRTOS 和其他的嵌入式 RTOSes 通常提供架构相关的、直接编程 MPU 区域的
API（通常会避免子区域或者原样提供）。FreeRTOS 可以被可选配置为使用
MPU。为了避免修改系统结构，即内核被编译为一个库并与程序链接，而不是维持稳定的用户/内核分离，系统调用指令（`SVC`）和它们最终的处理函数被内联进代码中，使得能够运行敏感的
MPU
修改指令。尽管这高效地促进了应用对内存访问的限制，并且可能增加稳定性，但它并没有保证安全性，因为保护是自主的。Safer
Sloth @safer-sloth 结合了内联陷阱和带有静态检查的 MPU
编程，用以确保陷阱仅用于内核期望的地方。 由于Safer Sloth 的应用是用 C
写的，这并不能防止劫持控制流的攻击（例如，自修改代码和缓冲区溢出）。这些系统为非恶意应用提供更好的可靠性，但是并没有针对安全性、混合关键性、多租户提供强隔离。

相比之下，Tock@multiprog-64kb 和 @io-virt 的 I/O 虚拟化工作使用 MPU
区域限制了应用可访问的内存。他们使用一种更加传统（非内联）的用户/内核态分离，使内核抽离出
MPU
编程，并简单地查清每个应用程序的代码和数据对连续区域的访问。#footnote[译注:这句按原文说法翻译相当抽象，对语序进行了一些调整。]这些系统，虽然简单，但并不支持动态共享关系，并且使得需要用于共享内存和虚拟化的
MPU 区域布局更加混乱复杂。

= 通过内存布局有效利用 MPU <III>
== 内存布局对 MPU 使用的影响 <III-A>

由于系统逐渐需要在不同的组件、不同的关键性和不同的来源之间加入更多的保护屏障，他们需要更多更复杂的对内存保护硬件的管理。例如，共享内存必须被创建在
VM 和 VMM
之间，而流式处理和发布者/订阅者系统必须创建基于通信模式的共享区域。这与组件（通常是一两个）显式地变成
MPU 区域来保护少量内存区域的传统嵌入式系统形成鲜明对比。

在提供细粒度的内存保护时，一个小问题是 MPU
对于对齐、子区域和大小的限制，规定了所有代码的内存布局，同时系统中的数据也显著影响到每个应用需要多少区域。@img:fig-2 描述了两个不同的应用内存布局和他们的共享内存（为了简单，在这个例子里我们忽略内核和
VMM
组件）。在第一个布局里面，内存被随意地排布，而应用需要比平台能提供的更多的区域（2个）。有些共享区域需要分别的
MPU
区域，而非2的幂次对齐的区域需要多个区域。红色的组件需要4个区域，而剩下的组件需要3个区域。在第二种布局中，内存以一定规则排列，从而减少提供所需的保护的区域的数量。在优化之后，没有任何一个组件使用超过两个区域，绿色的组件只需要一个内存区域。注意到为了实现这种最优化的布局，一段未使用的内存出现在红色和黄色组件之间。这代表区域内部碎片化导致的#emph[开支]，我们将在@VII
中继续学习。在当前系统中，设计者需要手动排布内存区域，或者系统镜像足够简单以至于区域位置不重要。

#figure(
  caption: [内存布局最优化。图中的每种颜色代表一个不同的组件，内存布局中的每个块都代指一块内存。内存块的大小是2的幂次方。如果同一个块中有两个颜色，那么这个块是这两个组件共享的。这个MPU有$|cal(R)|=2$，$S=4$，$cal(A)=(a_i mod s_i = 0)$，并且$s_i$必须是2的幂次方。内存布局下方的线展示了每个组件的MPU区域和子区域的配置，在“:”后面的是这个组件需要多少区域。如果一个子区域是活跃的，那么它会有一个实心卵形标记。],
  image("img/fig-2.gif"),
)<fig-2>

为了使得基于 MPU
的系统能提供更进一步的保护，我们将审视几个尝试在有限的区域内最小化内存消耗的。

== 内存安置 <III-B>
我们的第一个用于分配内存的方法是将 MPU
限制改写成一个可满足性模理论（Satisfiability Modulo
Theory，SMT）。尽管最终的解是#emph[精确]的------如果使用硬件限制内的区域和子区域的内存方案存在，它就会找到解------但这花了不实际的计算时间。对于简单的
MPU
配置（4个区域，4个子区域，3个组件），需要超过24小时才能找到解。因此，我们引入了一个贪心的启发式算法。

#[
  #let collapsible = $c o l l a p s i b l e$
  #let partners = $p a r t n e r s$
  #let merged = $m e r g e d$
  #let argmax = $op("arg"max, limits: #true)$
  #import "@preview/lovelace:0.2.0": *
  #algox(
    label-name: "算法1",
    caption: "内存地址分配启发式算法",
    pseudocode(
      no-number,
      [*输入*: $C$: 组件的集合, $A$: SRAM arena的集合],
      [*while*
        $| { c in C | mono("num_allocated_regions")(c) gt.eq |cal(R)|-1 }|$ *do*
      ],
      ind,
      [$collapsible = {c in C | exists_(a in A) mono("is_enabled")(a,c) }$],
      [*if* $|collapsible| = 0$ *then*],
      ind,
      [*return* $N o n e$],
      ded,
      [$c = argmax_(c in collapsible)|mono("num_allocated_regions")(c)|$],
      [$a_0 = argmax_(a in mono("accessible_enabled_arenas")(c))|mono("users")(a)|$],
      [$cal(O) = mono("accessible_enabled_arenas")(c) \\ a_0$],
      [$partners = {a in cal(O)|mono("subregions")(a) plus mono("subregions")(a_0) lt.eq S}$],
      [*if* $|partners|=0$ *then*],
      ind,
      [$mono("disable_arena")(c,a_0)$],
      [*continue*],
      ded,
      [$a_1 = argmax_(a in partners)|mono("users")(a_0)inter mono("users")(a)|$],
      [$a_merged = mono("merged_arenas")(a_0,a_1)$],
      [$A = (A - {a_0,a_1})union{a_merged}$],
      [$mono("reenable_all_arenas")()$],
      ded,
      [*end*],
      [*return* $mono("assign_addresses")(A)$],
    ),
  )
]

// #[
//   #import "@preview/lovelace:0.2.0": *
//   #algox(
//     label-name: "algorithm",
//     caption: [欧几里得辗转相除],
//     pseudocode(
//       no-number,
//       [#h(-1.25em) *input:* integers $a$ and $b$],
//       no-number,
//       [#h(-1.25em) *output:* greatest common divisor of $a$ and $b$],
//       [*while* $a != b$ *do*],
//       ind,
//       [*if* $a > b$ *then*],
//       ind,
//       $a <- a - b$,
//       ded,
//       [*else*],
//       ind,
//       $b <- b - a$,
//       ded,
//       [*end*],
//       ded,
//       [*end*],
//       [*return* $a$],
//     ),
//   )
// ]


展示了这个输入每个组件的内存区域的集合，并确定一个在满足系统MPU限制的前提下实现保护的解的算法。我们将一个#emph[arena]#footnote[译注: 个人词穷，觉得这个词不好翻译得和region有区分，因此保留。]定义为可被一段组件访问的带有特殊访问权限（可读或读写）的内存区域。Arena
包含组件代码和只读数据、可写数据、不同组件之间的共享内存区域，以及对应动态内存分配的系统堆。非常重要的是，这些arena指示了一种为通过运行时请求建立的组件的潜在的映射。

如果所有的组件都有少于$\| cal(R) \|$个arena，那么将arena看作区域没有影响。否则我们尝试将两个区域的arena合并成一个区域，然后用分离的子区域来维持arena之间的隔离。为了有效地利用@II-B 中引入的MPU，多个arena必须使用一个区域内的分离的子区域，因为这能减少组件所需的区域数量。如果一个组件需要太多的区域，我们必须决定它的哪些区域要和其他区域合并。因此我们选择一个有最多区域的组件（第5行）。在这个组件以内，我们选择和最多组件共享的arena。直觉上，去除对这个区域的需要会减少最大的组件的区域需求。为了寻找另一个可合并的区域（#emph[partner]），我们考虑这个组件的所有区域。然而，可能会出现和另一个区域合并时，所需要的子区域超过$S$的情况，这样必须重新开始搜索（9-11行）。通过为每一个组件-arena对维持一个#emph[enabled]布尔变量，我们确保了算法不会重复合并两个相同的arena。最后，我们选择用于合并的区域，这个区域有最多的使用它作为第一个区域（$a_0$）的组件相交。重复这个过程直到所有区域都能被子区域保护。

在这个时候，这个算法有一组arena到区域的映射。`assign_addresses`过程将区域按大小排序，然后按照2的幂次方对齐将他们排列在内存中。一个值得一提的优化是，将下一个区域的开头放在的前一个区域的#emph[最后使用]的子区域后面。虽然简单，但我们发现这个优化提高了将近4倍的内存利用率。

#strong[启发式次优。]我们比较了一定量的SMT 求解器和算法
1输出的解，并且发现了启发式算法次优的几个方面。和启发式算法相比，SMT算法往往：（1）使用一个大区域后面的连续的额外区域，由此产生一个非2的幂次方大小的子区域；（2）将不同大小的区域放进连续的子区域来最小化内部碎片化，以及（3）使得arena能够延伸到多个连续region，并且可能有变化的子区域大小。这些次优性可能指向一些能够适配有限数量的MPU区域/子区域和智能内存布局的内存量的系统配置，但是@algo:算法1
无法找到他们。因此，在@VII-D 中，我们将研究我们的贪心启发式算法在高效利用内存上的影响。

#figure(
  caption: [
    内存和区域布局工具组。这个工具组会接受组件的内存规格以及MPU/架构信息，然后转换成一个带有内存布局算法的链接器脚本。最终的可执行二进制文件会从链接器脚本产生。内存分配算法也产生一些共享内存管理器需要的信息。
  ],
  image("img/fig-3.gif"),
)<fig-3>

#strong[内存放置的工作流。]@img:fig-3 展示了每个组件、可能的共享的arena和硬件限制的特性是如何集成到@algo:算法1
中的。的输出被输入给一个生成系统镜像的连接器脚本，以及系统中引导动态请求的内存管理服务。

= 为硬件内存保护推广操作系统支持 <IV>

为了提供一种强隔离，我们适配了一个基于capability#footnote[译注: 个人找不到能传达类似意思的中文词，因此保留。]的安全性@prog-semantics
的现有的操作系统的访问控制抽象层，而不是一个现有的嵌入式RTOS的特别的接口。capability为基础的系统的核心性质包括：系统资源只能通过#emph[不可伪造的]capability引用，这些capability只在由别的已经拥有这个资源的组件#emph[委派]时才可以访问。所有系统内存和内核资源都通过capability访问，它们也可以用于实现基于#emph[封闭]@confinement
的强隔离。对于一个简单的、注重将大多数系统资源管理转移到用户层的系统，capability已经被验证是很好的@scale-pred
@fiasco @sel4 @eros。

这项研究使用一个基于PCTrie的机制来推广基于capability的内存访问控制，这个Composite中的机制——先前是MMU特有的——来控制MPU和MMU。为了简化内存并将动态内核内存分配移动到用户层，Composite使用内存retyping来实现#emph[用户级别]的#emph[内核内存]管理@scale-pred，其中绝大部分由seL4@sel4
启发而来。

== Composite 内核抽象 <IV-A>

Composite中的资源管理和隔离策略实现在用户层的组件中，这些组件通过capability访问并控制系统资源。在我们的系统中，系统调度器（也管理共享内存）和I/O管理器形成了概念性的虚拟机监视器，管理资源并确保RTOS
VM之间的隔离。通过映射内存、创建线程、以及创建通信端点，他们委派系统资源，1️以响应VM的请求。

#strong[内核对象和资源。]Composite内核有少量的内核对象：组件、线程、TCaps、通信端点（同步和异步），和两种不同类型的#emph[资源表]@scale-pred。资源表也是由capability作为索引的，映射到引用的内核资源。Composite有两种资源表：追踪内存访问权限的页表和追踪对内核资源（包括其他资源表）的访问的内核资源capability表。页表将加载/存储内存访问视作一个解析为对内核资源中物理内存一个特定的字的capability引用。内核资源capability表操作需要系统调用来在他们的资源上进行操作。每个组件根本上只是两个资源表的集合（一种一个）。

一个线程是线性执行的基本单位，而每个组件可以有0个或多个线程。一个拥有一个线程的capability的组件能够调度这个线程。通信端点有两种形式：（1）使用线程迁移@mach-thread
提供#emph[同步]通信的`sinv/ret`，以及（2）提供#emph[异步]事件通知的`asnd/rcv`，其中一个线程通过`asnd`#emph[发送]一个事件，激活一个使用`rcv`等待的线程。对资源表自身的操作包括构造和析构资源表（例如，创建一个新的组件），以及从一个资源表复制一个capability到另一个资源表。后者提供了组件之间的#emph[委派]，并且需要一个组件有一个客户的资源表的capability。

只有有一个客户的资源表的capability的组件才能委派给这个客户。这些组件组成了系统的#emph[资源管理器]。为了改编Composite来控制一个微控制器的MPU,我们将更新页表来提供更加灵活的追踪内存访问控制的方法，并更新内存管理资源管理器来使用这个更新后的抽象层。

== PCTries 作为MMU 和MPU的推广 <IV-B>

#strong[路径压缩的基数树（PCTrie）。]与通常的连续几层翻译固定位数地址的页表为基础的基数树相比，谨慎的页表和广义的压缩的基数树@guarded-page
翻译变化位数的地址。这实现了更加内存高效的表示，同时支持发散的地址空间，允许页的大小可以为2的任意次幂。我们系统中的基数树将地址映射到访问权限而不是物理地址；由于MPU并不进行地址翻译，访问权限是足够的。

基数树（也称为页表）将地址翻译经过一系列有$2^n$个条目的表，每个条目指向trie中的下一层节点。每一个节点翻译n位的地址，直到一个页被引用到（可能是一个超级页）。相比之下，PCTrie
忽略一些所有的可行的翻译都共享的位数的内部节点。结果是，这移除了页表节点中的“链”，而不是把跟踪地址共同前缀位数的节点需求传递下去。这在地址空间分散的时候尤其重要，可以节省空间和查询时间。大多数微控制器中的内存是分散的：大多数可寻址的内存和I/O处于4MB的区域内。在这种情况下，前10位对所有地址是相同的，因而可以省略上层节点。与页表中的超级页相似，一个地址中最不重要的位不需要节点，而是导致对更大的页的寻址。

#strong[MPU 区域和PCTrie]。PCTrie和II.B中提到的MPU模型有许多相似之处。ARM
Cortex-M
模型使用大小对齐的区域（类似超级页），并且要求区域是（因此子区域也是）2的幂次方大小的。PCTrie
在他们的超级页上也有相同的限制，因此可以直接被应用到生成MPU区域配置上。III-B中的静态内存布局保证了PCTrie不需要多于$|cal(R)| times S$个保护的内存区域。

#strong[作为PCTrie的页表。]页表相当于不省略翻译位的节点，并且支持基于低层的省略级别的位数大小的多重超级页大小的PCTrie。

= V. 隔离在受限的嵌入式系统中的实现 <V>
== PCTrie的实现 <V-A>

在x86平台上，Composite通常支持包括相互连接组成活动页表的分别分配的节点组成的页表。使用PCTries的目的在于（1）用少量的节点表示小内存系统的分散的内存地址，（2）消除基数树结点的分散的内核分配，以及相当重要地，（3）使得有效可预测的MPU变成成为可能。第一个目标通过PCTrie的路径压缩的特性实现，而第二个是通过内联PCTrie的节点内存到一个组件的capability表中的capability槽里。第三个则是通过在每次修改PCTrie时，维护一个整个PCTrie表示的区域和子区域的“摘要”来实现。

页表节点被动态分配为分离的页，并遵循硬件要求的格式。相比之下，由于与硬件不直接相关，PCTrie表示形式提供了更多的灵活性。每个PCTrie节点保存4个引用，指向内存区域，或者PCTrie中的其他节点，同时翻译2个位。每个引用包括省略的位数或者指向的内存区域的大小。

PCTrie节点表示法占用44个字节。Composite中的capability槽位可以是多种大小的，最大的大小（64字节）被用于存放完整的PCTrie节点。这使得组件可以避免为每个节点分配（retype、激活，以及管理）分散的内存
@scale-pred。重要的是，这意味着内存管理的开支被均摊到capability表的管理中，而通过移除页颗粒度控制，我们省下了大量的内存。用户层的库管理所有的页表管理细节（使用安全的内核API），这些库被改写以适应PCTrie。

#strong[高效的MPU更新。]ARMv7-M
处理器上的MPU是通过一组内存映射的寄存器编程的，叫做区域编号寄存器（RNR, Region
Number Register），区域基址寄存器（RBAR, Region Base Address
Register），以及区域属性和大小寄存器（RASR, Region Attribute and Size
Register）。RNR控制那个区域正在被编程（尽管RBAR有一个覆盖RNR的区域字段），而RBAR和RASR控制区域的开始地址、区域的大小，以及区域的子区域状态。加载这些寄存器并没有硬件辅助，所以他们必须被手动填充。

为了有效地编程这些寄存器，我们保存一个最高（顶级）capability中的PCTrie中所有区域的#emph[摘要]。这个摘要被储存在RBAR和RASR期望的特定MPU区域。当切换到一个新的组件时，PCTrie的头节点的摘要被读进CPU寄存器里，并被不经解释地写入MPU寄存器中。这使得在快速路径上能对MPU高效编程，但是依赖储存整个PCTrie的所有内存访问信息的摘要。为了提供这个不变量，所有的修改内存访问的PCTries操作#emph[同时]修改PCTrie#emph[和]概要。为了实现这个，每个PCTrie节点储存指向头部节点的反向指针，以及知道它自己表示的内存地址所需的局部信息。这个设计有一个副作用：系统不支持一个PCTrie#emph[内]的别名，而仅仅支持内存自身。如果有需要，用户层的管理PCTrie的库可以提供这种PCTrie内别名的语法支持。

RBAR/RASR在内存中连续排布，并且紧接着3个别名。基于这个性质，使用ARM Cortex-M7
处理器的多寄存器加载/存储（LDM/STM）指令可以以#emph[每次4个区域]的速度加快MPU编程。VII-A评估了我们对这些指令的应用与制造商提供的硬件抽象层代码的对比。

= 小规模的虚拟化 <VI>

Composite中的内存管理抽象为基于MPU的微控制器提供了可预测的保护。有了硬件保护，本地代码可以安全地运行在微控制器上。我们为资源有限的系统提供虚拟化的目标是为了：
- 实现与裸机相近的每个VM的#emph[高效且可预测的执行]；
- 使用#emph[层级调度] @hires 来维持VM之间的处理器隔离；
- 经由一个组件使用#emph[受保护的I/O去多路化]来调解I/O访问和隔离；
- 有效地使用内存布局来#emph[有效利用MPU]和内存隔离；以及
- 为#[VM间通信]提供设施。

为了实现这些目标，我们使用#emph[半虚拟化]@xen
来避免复杂和模拟原始硬件访问（例如，I/O访问，计时器访问以及中断）。Composite内核至关重要的承担访问监视器的职责——合理地限制资源访问——而我们实现一个用户层调度器和I/O管理器组件。通过修改硬件相关的平台层来利用VMM的资源，我们半虚拟化了FreeRTOS。@img:fig-4 展示了整个系统。

#figure(
  caption: [虚拟化基础设施。内存隔离使用黑色实线标出，逻辑隔离通过虚线标出，虚拟机管理器通过点线标出。],
  image("img/fig-4.gif"),
)<fig-4>

== CPU虚拟化 <VI-A>
由于Composite内核包含一个调度策略，每个FreeRTOS虚拟机（FreeRTOS/VM）使用它自己的调度器，同时使用Composite内核的调度设施。为了控制每个调度器是如何跨处理器多路复用的，我们使用层级调度。一个单独的VMM调度器组件在VM之间多路复用CPU。简单起见，根调度器使用固定优先级，预测式调度，与FreeRTOS相同。

我们的基础设施以来Composite对TCaps
@temp-cap，或者#emph[临时capability]的支持，它使得不同调度器之间时间的可控的委派
@temp-cap。这个基础设施使得两个我们充分利用的关键特性成为可能：（1）每个VM的调度器在它被委派的时间段内可以管理它自己的时钟中断，以及（2）如果VM独占一个硬件，则相应的硬件中断可以被安全地导向VM。请阅读@temp-cap
以了解有关如何安全地、正确地、高效地实现这一点的细节。

#strong[精细的时间访问]通过隔离系统组件，用户层不能直接访问需要权限的硬件资源。例如，原生的RTOS通常直接访问`SYSTICK`，它给出一个度量时间的量。然而，为了运行统计，以及正确地委派运行时间，每个用户级调度器必须维护时间。我们使用我们的平台（STM32F76IGT6）的`TIM4`计时器寄存器来提供一个周期精确的计数器。不幸的是，`TIM4`只有16位，而我们需要64位的时间戳，所以我们必须同时维护一个软件字节来跟踪高位字节。在实际实现中，当`TIM4`溢出中断发生时，我们将一个64位变量增加65536。当读取时间戳计数器时，我们读取这个64位变量，然后把它加到`TIM4`计数器值上来得到正确的时间戳。这个64位的时间戳可以被所有组件读取，但是只能由内核写入。

调度器在他们TCap分配的时间段内可以控制计时器中断。为了支持这个功能，当调度器派遣到一个线程，他们能够指定一个一次性计时器应该出现在不久后的未来。这些计时器中断被导向一个“调度器线程”。为了实现这些一次性编程的计时器，我们使用我们平台上的`TIM3`，因为它具有低功耗的对时间的编程，以及时钟周期准确性。

#strong[FreeRTOS CPU
  半虚拟化。]FreeRTOS自身被它的设计者抽象化以支持在不同架构的系统上的可移植实现。我们修改FreeRTOS的硬件抽象层以让它作为一个VM来运行，只依赖VMM和内核服务。我们提供了某些Composite相关的用于实现调度、计时器控制以及中断的最低级的函数的实现。FreeRTOS中的线程调度直接映射到Composite
的调度，并且只需要提供给VM的对线程的capability，同时计时器是使用上文提到的一次性计时器模拟的。中断是由Composite线程提供服务，他们在`rcv`端点上挂起并响应硬件中断而激活。

== I/O虚拟化 <VI-B>
基于前文在II-C中提到的，和I/O设备之间的交互是通过位于平台定义的内存地址的映射接口进行的。由于这些设备在内存中的对齐和颗粒度阻止了通过MPU的精细的隔离，我们使用一个隔离的I/O管理器组件来调节设备访问（见@img:fig-4 ）。这个I/O管理器被配置来允许每个VM访问设备的子集。每个VM通过对I/O管理器的受保护的组件调用来从一个设备读取数据，或者写入一个设备。我们当前把这个过程配置成静态的，更智能的preclude方式有待未来实现。

对于数据传输速率相对较低的I/O设备，数据通过Composite的同步调用，通过寄存器的方式传递。对于速率更高的设备，系统使用共享内存传输数据。如果多个VM从同一个设备读取数据，I/O管理器必须多路复用这个设备。因此设备的中断被发送给I/O管理器，然后它对订阅的VM发送软中断（通过`asnd`端点）。I/O管理器中的中断线程的优先级被设置成VM中最高的，以此接受类似@proc-aware-int
的中断。

#strong[FreeRTOS I/O
  虚拟化。]FreeRTOS中的I/O流程是平台特定的，而我们提供了Composite特定的调用I/O管理器的版本。I/O引起的数据和事件被暴露给FreeRTOS队列。

== 内存虚拟化 <VI-C>
由于系统是一个SASOS，它#emph[并不]提供地址虚拟化。因此，VMM的内存管理（简单起见，实现在调度器中）使用从III中衍生的内存布局。地址翻译硬件的缺失是引导这个设计的决定性因素。需求非重叠VM的一个主要限制是VM必须被重新链接（因此必须被提供为带符号信息的ELF对象），并且它们不能被以任何一种假设静态地址的方式写入。前者可能限制对专有软件的使用，而后者大多数是用于I/O访问，我们通过半虚拟化来寻址。

#strong[位置无关的VM。]为了实现一定程度上的地址虚拟化，我们研究软件支持。理想化的情况是每个VM的系统组件可以被一次性加载到闪存中，然后作为库被每个VM重用，以省下闪存中的空间（$N$个VM只使用一个镜像）。我们最初探讨了通过一个VM相关的全局偏移表（GOT,
Global Offset
Table）来维持每个全局变量的位置的方式。一个寄存器用于引用GOT，从而使得单个镜像能被用于不同的VM之间，而不同的GOT翻译镜像内的符号。然而这个方法并不令人满意，因为（1）跨平台编译器（`gcc`）为#emph[每个]变量产生昂贵的翻译，（2）RTOS经常依照他们运行的应用在编译时期进行特殊化，这阻止了我们使用一个通用镜像，且（3）基于较大的闪存内存来看，翻译的执行代价换取省下的内存并不值得。

== VM间通信 <VI-D>
过去的研究提供了可预测的VM间通信@xen-network
。我们避免典型的将VM间通信虚拟化为网络通信。这是由于嵌入式系统中多样的网络栈和协议，也是因为不是每个VM都想（或者应该有）一个消耗内存不小的网络栈。与之相反，我们提供一个接近端到端串行通信的抽象。这使用`sinv`同步调用端点实现，并且数据是通过寄存器传输的。这个抽象的核心在于低带宽数据移动，以及VM间事件提醒。

VM间更高带宽的数据移动使用共享内存区域。这些区域按照III中探讨的MPU区域的可能的布局方案建立。I/O管理器负责建立VM之间的通信端点，以及在必要的时候，为更高带宽的数据移动建立共享内存区域。

#strong[FreeRTOS
  通信半虚拟化。]至于剩下的I/O，通信整合在FreeRTOS的平台相关的代码中。来自其他VM的数据和事件被暴露为FreeRTOS队列。

= 评估 <VII>

#strong[硬件配置。]对于所有的评估，我们使用一个以216MHz运行的ARM
Cortex-M7微控制器（STM32F767IGT6），拥有512KB嵌入SRAM以及1024KB嵌入闪存。微控制器有一个16KB的指令缓存和16KB的数据缓存，总是启用。同时，为了加速从嵌入闪存获取指令的速度，闪存预获取加速器总是开启的。这个微控制器同时有一个双精度FPU，也总是开启的。我们使用`gcc`编译器5.4.1版本，为所有情况使用-O2优化标志。

所有的测量都重复了10000次，并计算了平均数、最大值以及标准差。这一节的所有的条形图展示了平均值（下方的暗色条），标准差（平均值条上显示的错误条），以及极值（上方亮色条）。

#strong[软件配置。]Composite系统一直是和VMM以及I/O管理器一起运行的，系统调度器一直有足够的未分类内存来满足其他组件的请求。两个VM被加载用于测量，每个VM运行一个或者更多线程。我们使用FreeRTOS
9.0.0，评估配置了MPU和没有MPU支持的系统。

== 微基准测试 <VII-A>
#strong[硬件损耗。]很多系统操作需要和一些硬件特性，例如权限模式，MPU，以及中断进行交互。为了理解操作系统和虚拟化的损耗，我们首先探究相关操作的硬件开支。这些结果提供了一个使用他们的软件抽象的性能#emph[下界]。@img:fig-5 包含了模式转换、中断损耗以及MPU编程的硬件损耗。

#figure(
  caption: [硬件开支。`int`是中断开支，`syscall`是系统调用开支，`MPU4`和`MPU8`分别表示优化后对4个和8个MPU区域编程的开支，以及`STM1`是ST Microelectronics硬件抽象层库对一个MPU区域编程的开支。],
  image("img/fig-5.gif"),
)<fig-5>

我们以裸机中断损耗来测量中断损耗。这个损耗是使用系统调用指令调用一个立即返回（使用`BR LX`指令）的系统调用。相比之下，系统调用损耗是使用Composite中被修改为立即返回的处理函数来测量的。这些代价中的差距包括系统调用中少量用于导向内核的逻辑运算，以及保存和恢复额外的寄存器。

MPU编程的代价包括更新 @V-A
中描述的MPU相关的寄存器。这个操作中的开支包括将会受影响的寄存器保存到栈里，对MPU寄存器编程，然后恢复受影响的寄存器。我们比较使用ST微电子（STM，ST
Microelectronics）提供的硬件抽象层（HAL，Hardware Abstraction
Layer）库来为MPU编程，以及我们的使用ARM多寄存器储存操作的优化版本。优化版本一次性编程4个寄存器，因此我们在报告中使用对4和8个区域编程的延迟。

#emph[讨论。]这些结果显示了我们用于提供隔离的硬件操作——包括MPU编程——的平均和最坏情况的延迟并不昂贵。值得注意的是，使用优化的MPU编程程序是重要的，因为STM
HAL中的实现有不必要的硬件损耗。这些测量结果的方差相对较小，但是最大值有两倍甚至三倍平均值情况。这有两个原因：（1）系统保存指令和数据缓存，以及一个闪存预取器，因此在缓存未命中出现时会导致抖动，尤其是在基准测试的前几轮中，缓存没有预热时。
（2）测量是通过16位时钟模拟的64位时间戳记录的，因此当它的中断到来时就会导致损耗。因此，在实际生产环境中，这些项目的最大值几乎不会出现，并且不会像展示的那么大。

#strong[系统操作开支。]为了研究在Composite和FreeRTOS的不同配置中，几个基础的系统抽象层的代价，我们比较：（1）直接使用系统调用API的Composite组件运行，（2）#emph[没有保护设施的]FreeRTOS，从而代表轻量级RTOS的开销，（3）由FreeRTOS配置用于实现显式MPU编程支持的FreeRTOS/MPU，以及（4）在VMM和CompositeOS之上运行半虚拟化的FreeRTOS的FreeRTOS/VM。这些在@img:fig-6 中展示。这些系统提供的核心操作包括中断处理、线程上下文切换，以及线程间通信（我们称之为IPC）。

#figure(
  caption: [在Composite，FreeRTOS,以及半虚拟化的FreeRTOS上主要系统操作的损耗。在这个比较中使用的Composite测量都是组件内测量。`ctx-r`是上下文切换一个来回的时间，`int`是中断延迟，`msgpass`是信息传递时间。对FreeRTOS来说，信息传递是`xQueueSend()`和`xQueueReceive()`；对于Composite，信息传递是`asnd()`和`rcv()`。],
  image("img/fig-6.gif"),
)<fig-6>

所有这些系统将中断执行分割为“上半部分”中断服务过程（ISR, Interrupt Service
Routine），和“下半部分”也就是在一个线程上下文中的执行。中断延迟由从ISR激活到对应的中断处理线程开始运行的时间间隔来测量。在Composite中，这是通过激活一个ISR中的内核“异步发送”（`asnd`）端点，然后用它激活一个阻塞等待在“接收”`rcv`端点上的线程。在FreeRTOS里，做法是相似的：ISR会使用`xQueueSendFromISR()`来发送到一个队列里，从而激活中断线程。在所有情况下，进入ISR和开始中断进程执行的间隔就是延迟。在FreeRTOS/VM中，这个延迟是用从Composite的硬件ISR执行，到一个半虚拟化的FreeRTOS线程从它的中断队列收到中断的间隔测量的。

#emph[讨论。]在很多情况下，FreeRTOS表示一个我们期望的更低的开支下界。它包含不受保护的设施，并且包含线程分发在内的一些过程的高度优化的版本。我们至少期待@img:fig-5 中的任何一个使用了基于MPU的保护的系统出现额外的延迟。结果显示Composite的操作大体上和FreeRTOS/MPU相近，除了线程上下文切换的代价。Composite和FreeRTOS/MPU中的上下文切换都显示出多于FreeRTOS的开支，这是因为系统调用和MPU编程的开支。FreeRTOS/VM同时显示出来自FreeRTOS（由于它的调度逻辑）#emph[和]Composite（它进行线程上下文切换）的开支。

有趣的是，Composite的信息传递操作更快，因为Composite系统是为了信息传递而高度优化的。至于中断处理延迟，FreeRTOS/VM的大多数开支来自于层级调度开支，这在大型系统上相对较小，但是在这里比较明显。这种开支的最大组成部分是由于Composite调度库中的一个当前策略，即总是尝试在处理一个中断线程的执行之后切换到一个调度器线程。由此导致的额外的线程分发开支提高了中断延迟。尽管这种设计不是必要的，我们还没有研究过为这个系统优化它。

#figure(
  caption: [中断开支 vs. 中断到达间隔。],
  image("img/fig-7.gif"),
)<fig-7>

为了更好地理解这些开支的实际影响，尤其是相关的中断，我们在@img:fig-7 中画出系统开支百分比与中断到达时间间隔之间的比较。请注意坐标轴从高中断到达间隔比率（低频率）到低中断到达间隔比率（高频率）。标签标出了真实设备的典型的中断间隔（来自产品数据表）。`Motion`是用于步态和动作检测的应用的加速度计。`HID`是人机界面设备，例如鼠标和键盘，`Sensor`包括加速度计在内的检测精细运动的传感器，`CAN`是一个CAN总线，而`Motor`是为了控制一个典型的步进电机。一个125kbps的拥有标准数据包大小的CAN总线，产生接近1kHz的中断。对于电机，我们假设一个约60rpm的普通电机，中断来自一个同轴的1000步每转的编码器。注意，FreeRTOS/MPU和Composite的线是几乎重合的。

#emph[讨论。]从图中我们可以得出结论，在这些大多数中断率的情况下，即使VM基础设施提供的代价高昂的隔离也显得可以接受，通常只有1%的开支。尽管如此，有些应用可能需要更低的中断响应时间，从而需要更有效的中断响应逻辑。在这种情况下，Composite原生功能的开支和FreeRTOS/MPU差不多，在提供强隔离的同时并不比FreeRTOS多太多。

#strong[Composite微基准测试。]为了更好地理解这些结果，我们在基础Composite系统上进行了一些测量（@img:fig-8 ）。在这一部分，我们讨论了下列Composite的操作：（1）组件内线程切换，（2）组件间线程切换，（3）同步调用进入时间，（4）同步调用返回时间，（5）中断延迟，（6）组件内异步通信时间，以及（7）组件间异步通信时间。

#figure(
  caption: [Composite系统操作的开支。`ctx1-r`和`ctx2-r`分别是是组件内和组件间线程上下文切换来回时间，而`sinv`是同步调用进入时间，`sret`是同步调用返回时间，`int`是中断延迟，`snd1`和`snd2`分别是组件内/间异步发送/接收时间。],
  image("img/fig-8.gif"),
)<fig-8>

组件内线程切换（`ctx1-r`）时间是使用Composite在同一组件的线程间分发来在两个线程间切换#emph[一个来回]的时间，而组件间线程切换（`ctx2-r`）时间是在两个位于不同保护域（被VMM调度器用于在VM间切换）的线程之间的。这两者的区别在于组件间线程切换会对MPU编程两次（在跨越保护域的时候），而组件内线程切换不对MPU进行编程。

在Composite里有两种ICP机制：通过线程迁移[20]的同步调用（`sinv/sret`），以及异步发送/接收（`asnd/rcv`）。两个组件之间的同步调用涉及组件之间的切换（包括MPU编程和系统调用），是最常见的内存隔离的组件之间的通信机制。`snd1`测量一个`asnd`和一个在`rcv`上等待的线程的激活之间的延迟。相比之下，`snd2`是在不同组件的线程之间，因此需要MPU编程。中断延迟`int`是从@img:fig-6 中复制的，展示了对中断延迟是与异步通信高度相关的这一直觉期望。这并不出人意料，因为这两个操作共享相同的抽象和代码。

== 虚拟化评估 <VII-B>

与FreeRTOS的半虚拟化一同构建在Composite中的虚拟化环境包含系统操作的延迟。图9更细致地探究了这些延迟。`ctx-r`展示了通过FreeRTOS的`taskYIELD()`进行的一个上下文切换来回。这个操作设计FreeRTOS调度和Composite中的调度库（以及分发）。

#figure(
  caption: [在半虚拟化的FreeRTOS（FreeRTOS/VM）中的主要系统操作的开支。`ctx-r`是上下文切换一个来回的时间，`vec2vm`是从Composite内核中断向量到VM内部的FreeRTOS中断向量的时间，`vec2thd`是从Composite内核中断向量到FreeRTOS接收线程的时间，`qsnd`是FreeRTOS队列发送/接收时间，而`isnd`是一次发送的代价。],
  image("img/fig-9.gif"),
)<fig-9>

我们集中在对虚拟化的两个方面的评估。首先，`vect2vm`是从Composite内核中断向量/ISR执行到VM中的FreeRTOS的ISR执行的时间。其次，`vect2thd`是从Composite
ISR，到FreeRTOS的接收线程执行的时间。我们可以从这个结果看出，大多数开支来自FreeRTOS#emph[内部]对这个中断的传递。这验证了我们先前的分析：当前的调度器实现总是在处理一个中断之后切换回一个“调度器线程”，并且导致了巨大的上下文切换代价。我们将在未来的工作中优化这一部分，但是正如我们在@img:fig-7 中所示，当前的代价对于许多I/O形式都是合理的。

最后，我们使用`xQueueSend()`和`xQueueReceive()`测量FreeRTOS/VM的任务间的通信代价，以及VM之间的代价。VM间通信是通过虚拟中断实现的。一个发送的VM发起一个同步调用到目标的VM，这个VM运行`xQueueSendFromISR()`来模拟中断接收。VM内通信测量是通过测量在发送线程中进入`xQueueSend()`和在接收线程中退出`xQueueReceive()`的时间差来进行的。VM间通信测量，测量封装在FreeRTOS半虚拟化层中的VM间调用（通过`sinv`和`ret`）来回代价。

#emph[讨论。]这些结果确认了在@img:fig-6 中看到的虚拟化环境的中断开支的来源主要是由于过度的线程上下文切换。`qsnd`和`isnd`通信机制之间的区别相当有趣：VM间通信比基于FreeRTOS
API的VM内通信快很多。注意到`isnd`是一个“来回”测量，而`qsnd`是一个“单程”测量。因此，我们的VM间通信是比VM内通信快两倍多。这大部分是因为VM间通信对优化的Composite
IPC机制的直接依赖。

== 半虚拟化复杂度 <VII-C>

半虚拟化依赖对被虚拟化操作系统的最底层的修改。在FreeRTOS/VM中，我们把FreeRTOS和平台相关的层移植到使用Composite的调度支持，计时器支持，以及I/O（通过对I/O管理器组件的调用）。这个平台实现有363行源代码（SLOC,
Source Lines of Code）。相比之下，我们的微控制器的裸机平台代码，无MPU版为483
SLOC，有MPU支持版为622
SLOC。尽管源代码行数不是一个完美的复杂度度量标准，我们还是得出结论，在Composite中半虚拟化FreeRTOS并不算大工作量，并且我们期望其他RTOS也可以被移植到这个系统。

== 内存虚拟化开支 <VII-D>

我们评估了这个系统在维持可预测性的同时以合理的开支提供的增强的隔离。这个系统的另一个重要方面是内存开支，以及如何高效地布局内存以最优地使用MPU来进行保护（@III）。除此之外，内核和组成VMM的所有组件都需要内存。我们将与一个作为基准的最小化FreeRTOS的`.text`，`.data`和`.bss`段进行比较。

#tablex(
  columns: (auto, auto, auto, auto),
  header: ([段名称], [`.text`], [`.data`], [`.bss`]),
  caption: [系统内存开支。],
  label-name: "table-1",
  [内核],
  [134727],
  [158],
  [36816],
  [调度器],
  [65012],
  [8192],
  [15612],
  [I/O管理器],
  [508],
  [4],
  [512],
  [FreeRTOS],
  [47920],
  [2652],
  [9196],
  [FreeRTOS/MPU],
  [58865],
  [3012],
  [8908],
  [FreeRTOS/VM],
  [38177],
  [12740],
  [17260],
)

#strong[内核和虚拟化开支。]@tbl:table-1
展示了每个软件组件的大小。内核和VMM组件增加了一个不变的内存开支，而FreeRTOS中的改变带来的开支随着VM的数量增加。半虚拟化的FreeRTOS消耗更多的RAM，这主要是因为Composite的用户级调度库静态分配所有线程；然而，它的代码大小缩小了，因为架构相关的代码被高效地移动到Composite内核里了。FreeRTOS进行系统资源（包括线程和队列）的动态分配，所以这个表并不是一个对内存需求的完美展示，因为FreeRTOS会在运行时需求更多。我们相信这些开支对大多数系统都是合理的。

#strong[内存分配算法的高效性。]

静态内存布局是使用@III 中尝试尽力利用可用的MPU区域和子区域的算法确定的。然而，MPU对齐和大小限制严重影响了M这些布局，从而产生了内部碎片。

为了评估我们系统的内存开支，我们测试5个不同的VM配置，使用3种不同的共享内存配置。这些配置都包含运行MiBench@mibench
应用的VM，并有如@tbl:table-3 所示的内存限制。每个#emph[小（small）]VM都包含一个MiBench应用。每个#emph[大（big）]VM都包含所有5个内存大小各异的MiBench应用。我们的5个不同的应用配置如下：（1）3小（`basicmath`，`dijkstra`，`gsm`），（2）3小1大（`basicmath`，`dijkstra`，`gsm`，`big`），（3）4小1大（`basicmath`，`dijkstra`，`gsm`，`pbmsrch`，`big`），（4）5小（`basicmath`，`dijkstra`，`gsm`，`pbmsrch`，`rijndael`），以及（5）5小1大（`basicmath`，`dijkstra`，`gsm`，`pbmsrch`，`rijndael`，`big`）。这些配置中的每个都同时包含内核和VMM组件。每个VM被编译成应用和半虚拟化的FreeRTOS。

由于用于VM间和VM/VMM间通信的共享内存至关重要并且使得MPU区域布局更加复杂，我们研究这三个共同的配置：
- 每个VM和I/O管理器之间的成对共享区域。
- 和第一项相同，但是同时包括将VM串成一个环的共享内存。这粗略地模拟了一个包含过滤器和变换的传感器处理管线。
- 和第一项相同，但是同时包括被配置为一个发布者-订阅者网络的内存，其中每个内存可以写入一个每个VM都可以读取的共享内存地址（VM之间成对共享）。

为了确定这些区域的大小，我们假定这些平台上256字节的数据包较为常见#footnote[例如，使用MQTT（http://mqtt.org/）通信的IoT设备。]。一个实际的环缓冲区大小——16——产生一个4096字节的共享区域。

为了评估每个配置中的开支，我们使用内存布局算法。我们给系统一个可配置的SRAM大小，然后使用逐渐减少的内存运行启发式算法，直到当给定$X K B$时它找不到一个解。每个配置使用的全部内存为$Y K B$，@tbl:table-2
包含了内存开支（$(X-Y)/Y$）。

#tablex(
  columns: (auto, auto, auto, auto),
  header: ([共享配置], [仅系统], [系统+链接], [系统+发布者-订阅者]),
  label-name: "table-2",
  caption: [内存布局开支由被使用的内存的比例作为度量。],
  [VM配置1],
  [0.528],
  [0.494],
  [0.494],
  [VM配置2],
  [0.600],
  [0.564],
  [0.564],
  [VM配置3],
  [0.534],
  [0.499],
  [0.499],
  [VM配置4],
  [0.400],
  [0.370],
  [0.370],
  [VM配置5],
  [0.487],
  [0.453],
  [0.453],
)

#emph[讨论。]2的幂次方大小的区域的内部碎片平均$25percent$的开支，而我们的超过了$tilde.basic 50 percent$。尽管这个开支是合理的（例如，与页表的内存、对齐和颗粒度需求相比），这一点也不最优。相比之下，我们最开始对这个算法的基于SMT方程的设计使用更简单的配置，则倾向于产生$tilde.basic 10 percent$数量级的开支。这个启发式算法的$tilde.basic 50 percent$开支代表了在一个合理的解和长运行时间之间的权衡。

#strong[VM可扩展性。]随着对隔离需求的增加，一个单一系统将会需要多个VM。为了评估VM数量增长的系统的可扩展性，我们考虑每个VM的大小，以及必要的MPU对齐参数的变化。每个FreeRTOS/VM（没有应用）可以放进32KB的内存块。如果所有的虚拟机都是空的，那么STM32F767IGT6（512KB
SRAM）可以放8个，同时包含内核和VMM组件，剩下128KB用于共享映射和动态分配。这表示一个仅基于系统开支的限制，而更大或更需要计算的应用实际上会导致更少的VM。即使对于现有的系统，如果一个系统有大量的应用并且希望将他们隔离到不同的VM中，这也是有用的。不论怎样，对这么小的系统来说，这仍然是令人惊讶的可扩展性。

为了理解#emph[带有]应用的系统的可扩展性，@tbl:table-3 包含了和半虚拟化的FreeRTOS一起编译的不同的MiBench@mibench
应用的内存需求。在实际的配置中，VM内的应用和VM的内存占用相近或者更小。因此，一个中等的微控制器可以轻松的容纳4个VM，而有更多SRAM（1MB或者更多）的高端微控制器可以轻松容下12个或者更多VM。

#tablex(
  caption: [VM内存开支。],
  label-name: "table-3",
  header: ([VM名称], [`.text`], [`.data`], [`.bss`]),
  columns: (auto, auto, auto, auto),
  [basicmath],
  [61961],
  [12740],
  [17260],
  [dijkstra],
  [64256],
  [12744],
  [57708],
  [gsm],
  [86545],
  [12932],
  [17260],
  [pbmsrch],
  [63264],
  [12744],
  [18284],
  [rijndael],
  [80576],
  [12748],
  [17260],
  [big],
  [193512],
  [12948],
  [59244],
)

= 相关工作 <VIII>

#strong[避免硬件保护。]许多内存有限的系统通过语言安全性提供隔离。这些包括TinyOS
@nesc 和 Tock
@multiprog-64kb。这些方式有个好处：软件bug可以通过软件检查来限制，这可以减少许多操作的开支。然而，这使得分离的代码的虚拟化更加困难。其他项目在微控制器上使用安全的语言，但是强调以性能和可预测性的代价换取可编程性，@micropython，@elua，@microej，@mjs。

相比之下，其他的嵌入式OS并不强调安全性，而是内存使用和/或动态更新@freertos，@dynamic-os，@nesc，@contiki。尽管这些维度也很重要，我们还是关注在多个组件或者虚拟机之间提供可预测的隔离的基础设施。值得一提，进行合理的基于区域的保护所需的静态内存布局，是在知道所有系统组件的前提下得出的。这使得动态更新更复杂；在运行时更新布局的能力将是未来的研究方向。

有些系统将保护域交互（IPC）简化成函数调用以追求性能，并且使用过程，或者协作调度
@dynamic-os，@nesc，@multiprog-64kb。这个设计决定在所有的代码都有很大的期望能够遵循低且有限的运行时间，否则这个并不抢占的性质会阻止临时的隔离。

#strong[显式管理MPU。]正如在@II-D 中提到的，许多嵌入式OS提供编程MPU特定区域的API.这种系统并不注重为MPU编程提供一个统一的接口，也不将这些设施和一个高校地使用MPU来进行共享和虚拟化的内存布局算法联系起来。

#strong[作为缓存的MPU。]先前版本的嵌入式Linux支持作为可访问区域的缓存的内存管理的MPU。线程能够创建比系统上区域更多的映射，而那些不#emph[活跃]的区域会在他们的内存被访问时引起中断。软件处理程序（类似软件TLB未命中）定义如何追踪区域，以及决定在一个新区域需要被激活时该丢弃哪个区域的区域替换策略。尽管这将MPU推广为任意数量的区域，这导致了和TLB未命中和硬件页表遍历类似的不可预测的开支。对于资源有限的微控制器，这种技术提供了对MMU编程范式的最大兼容性，但是可能导致不可预测的运行以及当内存访问以一定顺序进行时的巨大开支。本研究致力于使用一个静态分析，在保证可预测、无保护错误的嵌入式代码执行的同时，最大化利用MPU。

#strong[虚拟化支持。]据我们所知，这篇文章提出了第一个基于MPU的微控制器的虚拟化基础设施。和我们的I/O虚拟化类似，@io-virt
实现了一个处理I/O的FreeRTOS任务，而其他任务将他们的I/O访问导向它。相比之下，我们的研究注重一个实现CPU、内存和I/O三者全部的虚拟化基础设施。

= 结语 <IX>

这篇论文引入了一个支持对CPU、内存和I/O三个维度的强隔离的基础设施。我们展示了如何将一个略微有限的MPU，通过结合静态内存布局算法和一个泛化不同的硬件保护机制的高效内核的，有效地用于提供细粒度的隔离。这个VM基础设施支持半虚拟化的FreeRTOS，并且可以轻松扩展到8个VM实例。

#strong[致谢。]我们感谢匿名的审阅者和他们的有帮助的反馈，以及我们的引路人，他们极大地帮助了我们提高这篇文章的明确性。

#bib(bibfunc: bibliography("bib.yml"))

#show: appendix;

= 个人总结
这篇论文提出了一种在使用MPU作为内存安全硬件的微控制器上进行隔离和虚拟化的方法。

个人认为虚拟化/半虚拟化是当下这个强调SaaS/PaaS、微服务、横/纵向可扩展性的时代最有前景的课题之一。服务器端我理解范围内，Docker/Podman所代表的容器化技术，以及衍生出的buildx/docker compose，极大程度上简化了对开发环境的配置，缩短了发布流程。基于虚拟机运行的云服务器（ECS）也是堪称基础设施的架构。在这种嵌入式设备上进行虚拟化，我个人并没有看到很多直接的应用，但是觉得这项技术真的很酷。这篇论文契合了我当前兴趣的绝大部分：操作系统（虚拟化和隔离可以算作OS的一部分），以及硬件/嵌入式。

同样让我觉得比较有意思的是，在了解了FreeRTOS之后，我发现这并不是一个严格意义上的“Operating System”。我指的OS是类似Linux/Unix这种具有一个具体“内核”的操作系统（举一个我比较熟悉的例子大概就是`xv6`？）；FreeRTOS更像一个工具库。一定程度上这是因为没有基于MMU/页表提供的虚拟地址，应用并不能做到地址无关，因此也很难将一些传统操作系统的设计理念搬到虚拟机上。不过Composite可以做到在地址相关的情况下提供一个类“内核”，对此我还是比较好奇的。

关于这个启发式算法。我个人对算法并不是很敏感，但是我还是能看出来这个算法有一些贪心算法的影子。用贪心获得一个次优解/近似解还是比较人性化的设计了，不过我又对这个问题的复杂性产生了一些猜测，是NP问题？

翻译到一半的时候我在淘宝上买了两块开发板，2张树莓派的pico和1张pico 2。虽然这个级别的开发板还算便宜，但是买板子还是有点让人上头。我手头上还有一张来自遥远的2023年的树莓派4B，虽然只有2GB，跑一些小的服务还是够了（目前最高记录是一个不甚稳定的单人Minecraft服务器）。下一步可能我会考虑移植这篇文章的一些成果，到pico 2上（因为pico的Cortex-M0支持的MPU region还是太少了……），不过那还要等期末考完吧，可能我会跟作者老师沟通一下。

#let mail-link(mail) = link("mailto:" + mail, [#mail])

本文使用Typst进行排版，并对 #link("https://github.com/GrooveWJH/unofficial-sdu-thesis", [`unofficial-sdu-thesis`])进行了一些修改以适应课程作业的排版格式，感谢学长对该项目的贡献。源代码位于 #link("https://github.com/qwqFranzFox/pan18mpu-translate/blob/main/template/thesis.typ", [此处])。如果审阅老师有任何问题，可以通过#mail-link("qwqfranzfox@outlook.com")（个人邮箱）或#mail-link("202500130194@mail.sdu.edu.cn")（学校邮箱）联系我。

#pagebreak()

= 原文

// 导入原pdf
#let end = 13 + 1
#for i in range(1, end, step: 1) {
  image("../../1-pan18mpu.pdf", page: i)
}
